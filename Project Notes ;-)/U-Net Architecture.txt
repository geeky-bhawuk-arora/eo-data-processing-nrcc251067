ðŸ”¹ INPUT
Input shape: (3, 256, 256)
This means the model takes a 3-channel (RGB) image of size 256Ã—256 pixels.

ðŸ”¹ ENCODER (Contracting Path)
The encoder captures contextual features by progressively downsampling the input.

Each encoder block:
[Conv â†’ BatchNorm â†’ ReLU] Ã— 2: Two convolutional layers followed by batch normalization and ReLU activation. This helps learn features while stabilizing training.

MaxPool: Reduces the spatial size by half (e.g., 256Ã—256 â†’ 128Ã—128), allowing deeper feature learning and increasing receptive field.

Feature depth progression:
64 â†’ 128 â†’ 256 â†’ 512: As you go deeper, the number of feature channels increases, capturing more complex features. For example:

Block 1 output: 64 channels

Block 2 output: 128 channels

Block 3 output: 256 channels

Block 4 output: 512 channels

ðŸ”¹ DECODER (Expanding Path)
The decoder reconstructs the spatial details from the encoded features using upsampling and skip connections.

Each decoder block:
Upsample: Increases spatial resolution (e.g., 32Ã—32 â†’ 64Ã—64).

Concatenate Skip Connection: Merges corresponding feature map from encoder (same spatial size) to bring back spatial details lost during downsampling.

[Conv â†’ BN â†’ ReLU] Ã— 2: Refines the combined features.

Feature depth progression:
512 â†’ 256 â†’ 128 â†’ 64: Feature channels reduce as we go up, similar to encoder but in reverse.

ðŸ”¹ FINAL LAYER
Conv2D (1Ã—1): Reduces channel dimension to match the number of output classes (3 in your case: No Cloud, Cloud, Shadow).

Softmax (in inference): Applies softmax across the 3 channels per pixel to produce per-pixel class probabilities.

ðŸ”¹ VISUAL FLOW
vbnet
Copy
Edit
Input (3, 256, 256)
     â†“
Encoder:
[Conv-BN-ReLU] Ã—2 â†’ MaxPool
     â†“
64 â†’ 128 â†’ 256 â†’ 512 channels
     â†“
Bottleneck (maybe 1024 channels)
     â†‘
Decoder:
Upsample â†’ Skip â†’ [Conv-BN-ReLU] Ã—2
512 â†’ 256 â†’ 128 â†’ 64 channels
     â†‘
Final Conv2D (1x1) â†’ (3, 256, 256)
Softmax â†’ per-pixel class probabilities